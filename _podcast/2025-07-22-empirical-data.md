---
layout: post
title: "实证研究数据处理的过程标准化探索"
---

* TOC
{:toc}

## 写在前面

这个频道的出发点是，记录下我处理GLOC_24眼动实验数据的全过程。通过观察、分解数据处理、建模的全过程，描绘出一个可拓展到同类实证研究的R代码框架。概览的思路是：

1. 数据导入、清洗 --> 
2. 筛选出需要的列数据，整理排列为标签完整的行、列数据 --> 
3. 针对各个研究问题，存储各自所需数据的完整数据框 -->
4. 根据自变量、因变量的数据性质，划分几种主流的线性模型构建方法。每个方法包括数据的描述性统计、分布分析、固定和随机效应变量确认、初步拟合、拟合优度检验、数据变换、再次拟合、对比拟合优度、输出较优模型的统计结果。-->
5. 制图，使用 ggplot，根据数据特性，制作有区分度的图表。后期调整重点是比例、坐标轴值域、配色外观等。-->
6. 统计结果和制图的公式保存、结果输出，且全流程保存为 rmd 文档，写明过程，以便回溯。

这个概览的思路是和以前实验数据处理一脉相承的事情，虽然繁琐，但是并不陌生。然而这次想做的过程标准化探索，是借助AI大模型的力量，对已有的流程再做一次结构化处理。思路1：以工作流为基础，构建出帮助处理数据的智能体，以AI agent 为重要辅助，核心是搭建工作流和调用 LLM；思路2：以数据处理的逻辑块为基础，构建出半固定的流程界面，将AI 辅助固定在具体的任务上，目标产品是可视化的交互式网站界面，用户可以直接上传所有实验数据，在流程的引导下，半自动地描述数据、选择处理选项，完成全流程。

思路2 是我更想做到的，一个类似于“傻瓜式”的一站式数据处理网站，极大地有利于翻译实证研究者快速得出实验结果。这种形式的前驱是 Michael 那一套 Translog 数据放在 YAWAT 平台上一键导出的效果，但是 YAWAT 的数据是直接从 Translog 导出的，因此数据是从闭源到开源。而思路2想做的是从半开源（需要符合一定的数据特性，再加以描述）到闭源的效果。Translog 和 YAWAT 的缺点很明显，从数据报错到手工对齐的繁琐，再到导出的半原始数据，都造成了很多的不方便。我想做的新工具不见得能实际上产生更好的效果，但是，试一试吧，谁知道呢？

## 第一节：原始数据类型和处理思路 (2025-7-22)

和 Claude 聊了一下，把原始数据类型列出来，并给出处理思路，再导入到 napkin 中生成一个脑图，如下。

### 处理思路

<img src="{{chezvivian.github.io}}/class/assets/podcasts/empirical-data/1_data_type_process.png" alt="思路：数据类型和处理思路" width="500"/>  


### 数据类型

在2024年12月整月收集的实证数据，主要分为以下四类：

1. 眼动IA report (Eyelink导出)：包含每个被试、每个试次、每个兴趣区（IA）的汇总指标，如注视时长、首次注视时间等。
2. 被试访谈录音 (已转为文字)：包含被试的主观反馈，如困难度、策略描述等。
3. 被试译文文本：可用于评估翻译质量。
4. 被试背景信息文件 (Excel表格)：包含人口学信息、语言水平等。

其中最核心、影响实验结果的是第一类的眼动兴趣区数据，通常可以最快出结果（按照常规的混合效应线性模型构建方法），决定研究问题是否被验证，是否出了显著性结果。

之后的被试主观数据、译文质量两类数据的处理，以往需要非常多的手动工作，因此旷日持久，且结果不一定显著。但是，今年这次的流程创新有可能可以解决这个问题。

一方面是效率提高——访谈录音可以自动转录，且用统一标签的方法，快速提取有效信息，过程中可以使用LLM来协助；

另一方面译文质量的评估，以往是个老大难问题。因为翻译专家对译文的评估，即使基于同一个标准，比如 MQM, FAR等专业质量评估框架，个体的主观性往往非常强，很难形成较高的评分者信度。所以，今年也许可以尝试COMET等人工智能辅助评分的方法，让人工智能用统一的方法来评估质量。即使大概率会被质疑，但是效率、质量的平衡和统一，一定会有价值和意义。

### 各类数据的整合

为进行混合效应模型分析，需要将清洗后的多源数据整合到一张主表中。

目标形式：

- 混合效应模型通常每一行是一次被试-材料（或被试-材料-区域，依据分析层级）的观测。
- 核心变量包括：Subject（被试ID）、Text（材料/句子/段落ID）、Task (任务类型)、IA（如果按区域分析）、关键眼动指标（因变量）、以及协变量（如背景信息、访谈评分、译文评分等）。

整合方法：

- 主表结构选择：以‘被试-材料-IA’为主键，一份长表。
- 主表来源：以眼动IA report清洗得到的表为基础，因为它包含了最细致的观测层级。
- 数据合并：
    - 对于被试级别的数据（如背景信息、访谈评分），使用Subject作为匹配键进行合并（merge）。
    - 对于材料级别的数据（如译文评分），使用Subject-Item作为匹配键进行合并。
- 预期总表结构：
    - | Subject | Text | Task | IA | GazeDuration | ... | Accuracy | Fluency | InterviewDifficulty | LanguageLevel |


流程小结：
1. 逐份数据文件清理、整理成长表结构。
2. 用merge/join的方式合并为一份总表，确保主分析变量全部齐全。
3. 对关键分析维度进行检查（如每个被试、每个材料在每个IA下是否都齐全）。
4. 变量标准化/正态变换（如必要），为选择合适的混合效应模型做最后准备。

---